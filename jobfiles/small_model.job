#!/bin/bash

#SBATCH \--partition=gpu
#SBATCH \--gpus=1
#SBATCH \--job-name=DATASET
#SBATCH \--ntasks=1
#SBATCH \--cpus-per-task=18
#SBATCH \--time=04:00:00
#SBATCH --output=DL4NLP/jobfiles/output/small_model.out

module purge
module load 2022
module load Anaconda3/2022.05

ENV_NAME="DL4NLP2"
PYTHON_VERSION="3.10"

MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
DIR_NAME=Meta-Llama-3.1-8B-Instruct

# MODEL=google/gemma-2-9b-it
# DIR_NAME=gemma-2-9b-it

# Activate the new environment
echo "Activating the environment $ENV_NAME"
source "$(conda info \--base)/etc/profile.d/conda.sh"
conda activate $ENV_NAME
# pip install sentencepiece

echo "Running small_language_models.py"

HF_TOKEN=YOUR_HF_TOKEN

srun python DL4NLP/scripts/small_language_models.py \
    --file_path data_mini/$DIR_NAME/train.json \
    --model_name $MODEL \
    --mask_model 'T5-small' \
    --n_perturbations 5 \
    --detector_model $MODEL \
    --make_perturbations True \
    --denoise_with_llm True \
    --return_scores True \
    --hf_token $HF_TOKEN

srun python DL4NLP/scripts/small_language_models.py \
    --file_path data_mini/$DIR_NAME/valid.json \
    --model_name $MODEL \
    --mask_model 'T5-small' \
    --n_perturbations 5 \
    --detector_model $MODEL \
    --make_perturbations True \
    --denoise_with_llm True \
    --return_scores True \
    --hf_token $HF_TOKEN


srun python DL4NLP/scripts/small_language_models.py \
    --file_path data_mini/$DIR_NAME/test.json \
    --model_name $MODEL \
    --mask_model 'T5-small' \
    --n_perturbations 5 \
    --detector_model $MODEL \
    --make_perturbations True \
    --denoise_with_llm True \
    --return_scores True \
    --hf_token $HF_TOKEN
