## Exam preparation
(Feel free to edit)
### Week 1
Tasks:
- Text categorization
- Document summarization
- Machine Translation (50% of web pages are in langauges other than English)
- Question Answering

##### Prior to Deep Learning
- SVM, Decision Trees, Generative Bayesian Approahes, Maximum entropy approaches

Main advantage of NN: no feature engineering.
Disadvantage: large amounts of training data are needed & difficulty tracing errors.

#### Word-based models
Feed-Forward LM (FFNN)
Word Represenation embeddings
- language modeling
- word representation (embedding)

Disadvantage:
- Restricted to fixed sentence length
  
#### Sequence classification
CNN (Convolutional) -> supparize vectors in the top layer by pooling
- language modeling -> summarization and translation
- sentence classification

 
#### Sequence labeling
RNN language models
- summarization
- sequence labeling (POS,NER)
- machine translation

Encoder (CNN or RNN) / Decoder architecture (RNN) can summarize, or create a caption

#### Sequence-to-Sequence modeling
Neural maching translation (RNN and Transformer)
- Tranformers can do Q&A, and machine translation
  
#### Large Language Models
Fine Tuning

### Week 2
